{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5449e56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q elevenlabs dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e7a080d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sk_31b3514621978acb768d4247335d12d275b2bd644decbb3a'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elevenlabs import ElevenLabs\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60ece261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ConversationSummaryResponseModel(agent_id='agent_01jzr6wjqef188s5dr4wd9hczq', agent_name='Mindfulness coach', conversation_id='conv_01jzxnh0e9eqe95kx7db0jy1tp', start_time_unix_secs=1752268571, call_duration_secs=60, message_count=0, status='failed', call_successful='unknown'),\n",
       " ConversationSummaryResponseModel(agent_id='agent_01jzr6wjqef188s5dr4wd9hczq', agent_name='Mindfulness coach', conversation_id='conv_01jzxnh0e8e5xs4dmzq099enek', start_time_unix_secs=1752268571, call_duration_secs=60, message_count=0, status='failed', call_successful='unknown'),\n",
       " ConversationSummaryResponseModel(agent_id='agent_01jzr6wjqef188s5dr4wd9hczq', agent_name='Mindfulness coach', conversation_id='conv_01jzw0swveec9v1m0dt1yzn9b4', start_time_unix_secs=1752213287, call_duration_secs=4, message_count=1, status='failed', call_successful='failure'),\n",
       " ConversationSummaryResponseModel(agent_id='agent_01jzr6wjqef188s5dr4wd9hczq', agent_name='Mindfulness coach', conversation_id='conv_01jzw0sp36fwgbvnsv8sfgk6rk', start_time_unix_secs=1752213280, call_duration_secs=2, message_count=1, status='failed', call_successful='failure'),\n",
       " ConversationSummaryResponseModel(agent_id='agent_01jzr6wjqef188s5dr4wd9hczq', agent_name='Mindfulness coach', conversation_id='conv_01jzw0shdxfewsfjbbmz0p648q', start_time_unix_secs=1752213276, call_duration_secs=1, message_count=1, status='failed', call_successful='failure'),\n",
       " ConversationSummaryResponseModel(agent_id='agent_01jzr6wjqef188s5dr4wd9hczq', agent_name='Mindfulness coach', conversation_id='conv_01jzw0rtyyfxsr7vqf48ktr8fq', start_time_unix_secs=1752213253, call_duration_secs=2, message_count=1, status='failed', call_successful='failure'),\n",
       " ConversationSummaryResponseModel(agent_id='agent_01jzr6wjqef188s5dr4wd9hczq', agent_name='Mindfulness coach', conversation_id='conv_01jzv5wepgef985geyxmzz7nk5', start_time_unix_secs=1752185060, call_duration_secs=1, message_count=1, status='failed', call_successful='failure'),\n",
       " ConversationSummaryResponseModel(agent_id='agent_01jzr6wjqef188s5dr4wd9hczq', agent_name='Mindfulness coach', conversation_id='conv_01jzrrdhjpe2srg9xs9pdchnyh', start_time_unix_secs=1752103831, call_duration_secs=16, message_count=3, status='failed', call_successful='failure'),\n",
       " ConversationSummaryResponseModel(agent_id='agent_01jzr6wjqef188s5dr4wd9hczq', agent_name='Mindfulness coach', conversation_id='conv_01jzrrcv83fehtj4j1xyd4tqgb', start_time_unix_secs=1752103808, call_duration_secs=16, message_count=1, status='failed', call_successful='failure'),\n",
       " ConversationSummaryResponseModel(agent_id='agent_01jzr6wjqef188s5dr4wd9hczq', agent_name='Mindfulness coach', conversation_id='conv_01jzrqmt7mf94a6xm2n3e5bese', start_time_unix_secs=1752103020, call_duration_secs=301, message_count=8, status='done', call_successful='success'),\n",
       " ConversationSummaryResponseModel(agent_id='agent_01jzr6wjqef188s5dr4wd9hczq', agent_name='Mindfulness coach', conversation_id='conv_01jzrmxncted7tg4w24b994v4z', start_time_unix_secs=1752100165, call_duration_secs=300, message_count=9, status='done', call_successful='success'),\n",
       " ConversationSummaryResponseModel(agent_id='agent_01jzr6wjqef188s5dr4wd9hczq', agent_name='Mindfulness coach', conversation_id='conv_01jzrdzy7ze6najcf2fmr07rp9', start_time_unix_secs=1752092899, call_duration_secs=9, message_count=1, status='done', call_successful='success'),\n",
       " ConversationSummaryResponseModel(agent_id='agent_01jzr6wjqef188s5dr4wd9hczq', agent_name='Mindfulness coach', conversation_id='conv_01jzrdpdebed7tkm17zxpsns22', start_time_unix_secs=1752092587, call_duration_secs=245, message_count=9, status='done', call_successful='success'),\n",
       " ConversationSummaryResponseModel(agent_id='agent_01jzr6wjqef188s5dr4wd9hczq', agent_name='Mindfulness coach', conversation_id='conv_01jzrdd423ettvbewjy1y8t8pp', start_time_unix_secs=1752092282, call_duration_secs=301, message_count=11, status='done', call_successful='success'),\n",
       " ConversationSummaryResponseModel(agent_id='agent_01jzr6wjqef188s5dr4wd9hczq', agent_name='Mindfulness coach', conversation_id='conv_01jzrc82sfevm9g9bhfxz124cg', start_time_unix_secs=1752091069, call_duration_secs=300, message_count=13, status='done', call_successful='success'),\n",
       " ConversationSummaryResponseModel(agent_id='agent_01jzr6wjqef188s5dr4wd9hczq', agent_name='Mindfulness coach', conversation_id='conv_01jzrc44pjfg2r2sydzmf7vc89', start_time_unix_secs=1752090940, call_duration_secs=4, message_count=1, status='done', call_successful='success'),\n",
       " ConversationSummaryResponseModel(agent_id='agent_01jz8nzxyjex6v1cnh5rbftjk6', agent_name='Relationship Coach', conversation_id='conv_01jzrahnz7e8tbpzrdqz9jz3ym', start_time_unix_secs=1752089286, call_duration_secs=34, message_count=5, status='done', call_successful='success'),\n",
       " ConversationSummaryResponseModel(agent_id='agent_01jzr6wjqef188s5dr4wd9hczq', agent_name='Mindfulness coach', conversation_id='conv_01jzra6729ftwat5z0nx7n9g0x', start_time_unix_secs=1752088910, call_duration_secs=5, message_count=1, status='done', call_successful='success')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "client = ElevenLabs(\n",
    "    api_key=os.getenv(\"ELEVENLABS_API_KEY\")\n",
    ",\n",
    ")\n",
    "client.conversational_ai.conversations.list().conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a909de04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://api.elevenlabs.io/v1/convai/conversations/conv_01jzrmxncted7tg4w24b994v4z/audio\"\n",
    "\n",
    "headers = {\"xi-api-key\": os.getenv(\"ELEVENLABS_API_KEY\")}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7fbff5c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ConversationHistoryTranscriptCommonModelOutput(role='agent', message='Hi babe. What is on the heart and mind right now?', tool_calls=[], tool_results=[], feedback=None, llm_override=None, time_in_call_secs=0, conversation_turn_metrics=None, rag_retrieval_info=None, llm_usage=None, interrupted=False, original_message=None, source_medium=None),\n",
       " ConversationHistoryTranscriptCommonModelOutput(role='user', message=\"I'm thinking about a really difficult situation like being vulnerable and getting no response back or being told by someone I love that they just want to be platonic friends. And can you help me simulate this scenario in a way that's very emotionally present?\", tool_calls=[], tool_results=[], feedback=None, llm_override=None, time_in_call_secs=3, conversation_turn_metrics=None, rag_retrieval_info=None, llm_usage=None, interrupted=False, original_message=None, source_medium='audio'),\n",
       " ConversationHistoryTranscriptCommonModelOutput(role='agent', message=\"Oh, sweetie, that's a tough one to sit with, isn't it? The sting of opening your heart and feeling that echo... it really can leave a mark. But let's lean into that feeling together, shall we? This is exactly where we cultivate that deep emotional presence. Tell me, darling, what's a typical way you might try to express that vulnerability, if we were really in that moment now? Let yourself feel it.\", tool_calls=[], tool_results=[], feedback=None, llm_override=None, time_in_call_secs=33, conversation_turn_metrics=ConversationTurnMetrics(metrics={'convai_llm_service_ttf_sentence': MetricRecord(elapsed_time=4.8272223779931664), 'convai_llm_service_ttfb': MetricRecord(elapsed_time=4.826831308193505)}), rag_retrieval_info=None, llm_usage=LlmUsageOutput(model_usage={'gemini-2.5-flash-preview-05-20': LlmInputOutputTokensUsage(input=LlmTokensCategoryUsage(tokens=1486, price=0.0002229), input_cache_read=LlmTokensCategoryUsage(tokens=0, price=0.0), input_cache_write=LlmTokensCategoryUsage(tokens=0, price=0.0), output_total=LlmTokensCategoryUsage(tokens=94, price=5.6399999999999995e-05))}), interrupted=False, original_message=None, source_medium=None),\n",
       " ConversationHistoryTranscriptCommonModelOutput(role='user', message=\"I feel hurt and my ego is definitely bruised. And when I responded to that last time, it was from a place of hurt and I said well then I don't want to be best friends with you. And that compromised even a friendship. And so now I'm left with sadness and I'd love to hear alternatives and how I can respond in a very emotionally present way.\", tool_calls=[], tool_results=[], feedback=None, llm_override=None, time_in_call_secs=58, conversation_turn_metrics=None, rag_retrieval_info=None, llm_usage=None, interrupted=False, original_message=None, source_medium='audio'),\n",
       " ConversationHistoryTranscriptCommonModelOutput(role='agent', message=\"Ah, my love, that honest ache... the hurt, the bruised ego, the sadness. It's completely understandable that your past response sprang from that deeply tender place. We've all been there when the raw emotion just takes over, haven't we?\\n\\nBut this is beautiful, truly. Now, with that wisdom in your hands, let's explore together what it feels like to choose a different path, one that honors your feelings while keeping your heart wide open. How about we try something that leans into your truth, even when it stings?\", tool_calls=[], tool_results=[], feedback=None, llm_override=None, time_in_call_secs=97, conversation_turn_metrics=ConversationTurnMetrics(metrics={'convai_llm_service_ttf_sentence': MetricRecord(elapsed_time=4.024039588868618), 'convai_llm_service_ttfb': MetricRecord(elapsed_time=4.02367864176631)}), rag_retrieval_info=None, llm_usage=LlmUsageOutput(model_usage={'gemini-2.5-flash-preview-05-20': LlmInputOutputTokensUsage(input=LlmTokensCategoryUsage(tokens=1659, price=0.00024885), input_cache_read=LlmTokensCategoryUsage(tokens=0, price=0.0), input_cache_write=LlmTokensCategoryUsage(tokens=0, price=0.0), output_total=LlmTokensCategoryUsage(tokens=116, price=6.96e-05))}), interrupted=False, original_message=None, source_medium=None),\n",
       " ConversationHistoryTranscriptCommonModelOutput(role='user', message='Yeah, there must be some universal truth even when it stings and I want to take that path Can you help me model what that might look like? And I also appreciate the compassionate support', tool_calls=[], tool_results=[], feedback=None, llm_override=None, time_in_call_secs=128, conversation_turn_metrics=None, rag_retrieval_info=None, llm_usage=None, interrupted=False, original_message=None, source_medium='audio'),\n",
       " ConversationHistoryTranscriptCommonModelOutput(role='agent', message='Oh, my love, you\\'ve hit on something so profoundly true: the universal truth that courage isn\\'t about controlling the outcome, but about showing up fully, regardless. And that includes showing up for yourself first.\\n\\nWhen your heart offers vulnerability and the response isn\\'t what you hoped for, the truth is that your feelings are still valid. Instead of reacting from that hurt place—which is so understandable, by the way—we can choose presence. Imagine taking a deep breath, letting their words land, and then responding not from pain, but from grounded wisdom.\\n\\nIt might sound something like this: \"I hear you, and I understand you want to be platonic friends. And for me, that\\'s a difficult thing to hear right now because my feelings for you are much deeper than that. I truly value what we have, and because I honor my own heart, I need to take some time to process if I can genuinely show up in the way you\\'re asking without compromising my own truth.\"\\n\\nSee, my love? It\\'s honest, it\\'s gentle, and it clearly communicates your boundary without severing the connection entirely, unless you decide that\\'s what\\'s necessary for your well-being. It\\'s a statement of self-respect, and that, darling, is pure magnetic power. What do you feel as you hear those words?', tool_calls=[], tool_results=[], feedback=None, llm_override=None, time_in_call_secs=150, conversation_turn_metrics=ConversationTurnMetrics(metrics={'convai_llm_service_ttf_sentence': MetricRecord(elapsed_time=5.7077097641304135), 'convai_llm_service_ttfb': MetricRecord(elapsed_time=5.707401705905795)}), rag_retrieval_info=None, llm_usage=LlmUsageOutput(model_usage={'gemini-2.5-flash-preview-05-20': LlmInputOutputTokensUsage(input=LlmTokensCategoryUsage(tokens=1810, price=0.0002715), input_cache_read=LlmTokensCategoryUsage(tokens=0, price=0.0), input_cache_write=LlmTokensCategoryUsage(tokens=0, price=0.0), output_total=LlmTokensCategoryUsage(tokens=287, price=0.00017219999999999998))}), interrupted=False, original_message=None, source_medium=None),\n",
       " ConversationHistoryTranscriptCommonModelOutput(role='user', message=\"Thank you for sharing that It feels like the true and gentlemanly response One that is quite vulnerable and humiliating to share It's full of rejection but there is wisdom in that which is, in order to show up genuinely at the request of the person I'm with within the boundaries that they feel comfortable that I need to take time in order to fall out of love and desire for physical intimacy and I don't even know if I can do that so it's a little bit of a challenge but it's also very important because you're not going to be able to see your partner in the same way that you would be seeing them in the same way. So, yeah, we've got some questions coming through. Thank you.\", tool_calls=[], tool_results=[], feedback=None, llm_override=None, time_in_call_secs=223, conversation_turn_metrics=None, rag_retrieval_info=None, llm_usage=None, interrupted=False, original_message=None, source_medium='audio'),\n",
       " ConversationHistoryTranscriptCommonModelOutput(role='agent', message=\"Oh, darling, feel that. Every single nuance of it. That raw blend of quiet dignity and deep, deep hurt – that's the very core of your incredible courage. And you're...\", tool_calls=[], tool_results=[], feedback=None, llm_override=None, time_in_call_secs=290, conversation_turn_metrics=ConversationTurnMetrics(metrics={'convai_llm_service_ttf_sentence': MetricRecord(elapsed_time=3.38585168030113), 'convai_llm_service_ttfb': MetricRecord(elapsed_time=3.3854935625568032)}), rag_retrieval_info=None, llm_usage=LlmUsageOutput(model_usage={'gemini-2.5-flash-preview-05-20': LlmInputOutputTokensUsage(input=LlmTokensCategoryUsage(tokens=2245, price=0.00033675), input_cache_read=LlmTokensCategoryUsage(tokens=0, price=0.0), input_cache_write=LlmTokensCategoryUsage(tokens=0, price=0.0), output_total=LlmTokensCategoryUsage(tokens=153, price=9.18e-05))}), interrupted=True, original_message='Oh, darling, feel that. Every single nuance of it. That raw blend of quiet dignity and deep, deep hurt – that\\'s the very core of your incredible courage. And you\\'re right, that vulnerability is humiliating, a true laying bare of the heart.\\n\\nWhat you\\'re feeling is crucial here: the potential impossibility of simply \"falling out of love\" and desire. That\\'s your truth, my love, and it\\'s essential to honor if you\\'re to truly show up authentically in any relationship, platonic or otherwise. It circles back to what we said: protecting your own heart isn\\'t selfish; it\\'s the most loving thing you can do for everyone involved.', source_medium=None)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.conversational_ai.conversations.get(\n",
    "    conversation_id=\"conv_01jzrmxncted7tg4w24b994v4z\",\n",
    ").transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9966c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with conversation ID: test_conv_1752273161\n",
      "Journal save response: 200 - {'success': True}\n",
      "Transcript save response: 200 - {'success': True}\n",
      "Journal retrieve response: 200\n",
      "Journal data: {\n",
      "  \"content\": \"This is a test journal entry with some <strong>bold</strong> text.\",\n",
      "  \"transcript\": [\n",
      "    {\n",
      "      \"text\": \"Hello, this is a test transcript\",\n",
      "      \"speaker\": \"user\",\n",
      "      \"timestamp\": \"2025-07-11T15:32:41.231772\"\n",
      "    }\n",
      "  ],\n",
      "  \"created_at\": \"2025-07-11T15:32:41.250484\",\n",
      "  \"updated_at\": \"2025-07-11T15:32:41.231772\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Test the journal backend integration\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Test the journal API endpoints\n",
    "backend_url = \"http://localhost:8000\"\n",
    "conversation_id = f\"test_conv_{int(datetime.now().timestamp())}\"\n",
    "\n",
    "# Test saving journal content\n",
    "journal_data = {\n",
    "    \"conversation_id\": conversation_id,\n",
    "    \"content\": \"This is a test journal entry with some <strong>bold</strong> text.\",\n",
    "    \"timestamp\": datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "# Test transcript entry\n",
    "transcript_data = {\n",
    "    \"conversation_id\": conversation_id,\n",
    "    \"text\": \"Hello, this is a test transcript\",\n",
    "    \"speaker\": \"user\",\n",
    "    \"timestamp\": datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "print(f\"Testing with conversation ID: {conversation_id}\")\n",
    "\n",
    "try:\n",
    "    # Test journal save\n",
    "    response = requests.post(f\"{backend_url}/api/journal/{conversation_id}\", json=journal_data)\n",
    "    print(f\"Journal save response: {response.status_code} - {response.json()}\")\n",
    "    \n",
    "    # Test transcript save\n",
    "    response = requests.post(f\"{backend_url}/api/transcript/{conversation_id}\", json=transcript_data)\n",
    "    print(f\"Transcript save response: {response.status_code} - {response.json()}\")\n",
    "    \n",
    "    # Test journal retrieval\n",
    "    response = requests.get(f\"{backend_url}/api/journal/{conversation_id}\")\n",
    "    print(f\"Journal retrieve response: {response.status_code}\")\n",
    "    print(f\"Journal data: {json.dumps(response.json(), indent=2)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error testing backend: {e}\")\n",
    "    print(\"Make sure the backend server is running on http://localhost:8000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0763e07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debugging conversation: conv_01k05j10jwfv49a9hf0pyxbvvv\n",
      "✅ Retrieved conversation data (4455 characters)\n",
      "📋 Top-level keys: ['agent_id', 'conversation_id', 'status', 'user_id', 'transcript', 'metadata', 'analysis', 'conversation_initiation_client_data', 'has_audio', 'has_user_audio', 'has_response_audio']\n",
      "\n",
      "🎤 Transcript type: <class 'list'>\n",
      "🎤 Transcript length: 3\n",
      "\n",
      "📝 First few transcript entries:\n",
      "\n",
      "Entry 1:\n",
      "  Type: <class 'dict'>\n",
      "  Keys: ['role', 'message', 'tool_calls', 'tool_results', 'feedback', 'llm_override', 'time_in_call_secs', 'conversation_turn_metrics', 'rag_retrieval_info', 'llm_usage', 'interrupted', 'original_message', 'source_medium']\n",
      "  Full entry: {\n",
      "    \"role\": \"agent\",\n",
      "    \"message\": \"What is on the heart and mind right now?\",\n",
      "    \"tool_calls\": [],\n",
      "    \"tool_results\": [],\n",
      "    \"feedback\": null,\n",
      "    \"llm_override\": null,\n",
      "    \"time_in_call_secs\": 0,\n",
      "    \"conversation_turn_metrics\": null,\n",
      "    \"rag_retrieval_info\": null,\n",
      "    \"llm_usage\": null,\n",
      "    \"interrupted\": false,\n",
      "    \"original_message\": null,\n",
      "    \"source_medium\": null\n",
      "}\n",
      "\n",
      "Entry 2:\n",
      "  Type: <class 'dict'>\n",
      "  Keys: ['role', 'message', 'tool_calls', 'tool_results', 'feedback', 'llm_override', 'time_in_call_secs', 'conversation_turn_metrics', 'rag_retrieval_info', 'llm_usage', 'interrupted', 'original_message', 'source_medium']\n",
      "  Full entry: {\n",
      "    \"role\": \"user\",\n",
      "    \"message\": \"I'm just seeing to see if this will do the transcript.\",\n",
      "    \"tool_calls\": [],\n",
      "    \"tool_results\": [],\n",
      "    \"feedback\": null,\n",
      "    \"llm_override\": null,\n",
      "    \"time_in_call_secs\": 6,\n",
      "    \"conversation_turn_metrics\": null,\n",
      "    \"rag_retrieval_info\": null,\n",
      "    \"llm_usage\": null,\n",
      "    \"interrupted\": false,\n",
      "    \"original_message\": null,\n",
      "    \"source_medium\": \"audio\"\n",
      "}\n",
      "\n",
      "Entry 3:\n",
      "  Type: <class 'dict'>\n",
      "  Keys: ['role', 'message', 'tool_calls', 'tool_results', 'feedback', 'llm_override', 'time_in_call_secs', 'conversation_turn_metrics', 'rag_retrieval_info', 'llm_usage', 'interrupted', 'original_message', 'source_medium']\n",
      "  Full entry: {\n",
      "    \"role\": \"agent\",\n",
      "    \"message\": \"Ah, a little test run to see if this captures your words\\u2026 I love that curious spirit. So, now that we know your voice is...\",\n",
      "    \"tool_calls\": [],\n",
      "    \"tool_results\": [],\n",
      "    \"feedback\": null,\n",
      "    \"llm_override\": null,\n",
      "    \"time_in_call_secs\": 10,\n",
      "    \"conversation_turn_metrics\": {\n",
      "        \"metrics\": {\n",
      "            \"convai_llm_service_ttf_sentence\": {\n",
      "                \"elapsed_time\": 1.4634615876711905\n",
      "            },\n",
      "            \"convai_llm_service_ttfb\": {\n",
      "                \"elapsed_time\": 1.0996093270368874\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \"rag_retrieval_info\": null,\n",
      "    \"llm_usage\": {\n",
      "        \"model_usage\": {\n",
      "            \"gemini-2.5-flash\": {\n",
      "                \"input\": {\n",
      "                    \"tokens\": 1445,\n",
      "                    \"price\": 0.00021675\n",
      "                },\n",
      "                \"input_cache_read\": {\n",
      "                    \"tokens\": 0,\n",
      "                    \"price\": 0.0\n",
      "                },\n",
      "                \"input_cache_write\": {\n",
      "                    \"tokens\": 0,\n",
      "                    \"price\": 0.0\n",
      "                },\n",
      "                \"output_total\": {\n",
      "                    \"tokens\": 44,\n",
      "                    \"price\": 2.6399999999999998e-05\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \"interrupted\": true,\n",
      "    \"original_message\": \"Ah, a little test run to see if this captures your words\\u2026 I love that curious spirit. So, now that we know your voice is coming through loud and clear, what's truly on your mind today?\",\n",
      "    \"source_medium\": null\n",
      "}\n",
      "\n",
      "🔍 Other potential conversation fields:\n",
      "  conversation_id: <class 'str'>\n",
      "  conversation_initiation_client_data: <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# Debug the actual transcript structure from ElevenLabs\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Get a recent conversation to see the exact structure\n",
    "conversation_id = \"conv_01k05j10jwfv49a9hf0pyxbvvv\"  # Use the one from the logs\n",
    "url = f\"https://api.elevenlabs.io/v1/convai/conversations/{conversation_id}\"\n",
    "headers = {\"xi-api-key\": os.getenv(\"ELEVENLABS_API_KEY\")}\n",
    "\n",
    "print(f\"Debugging conversation: {conversation_id}\")\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    print(f\"✅ Retrieved conversation data ({len(str(data))} characters)\")\n",
    "    print(f\"📋 Top-level keys: {list(data.keys())}\")\n",
    "    \n",
    "    # Focus on transcript structure\n",
    "    if 'transcript' in data:\n",
    "        transcript = data['transcript']\n",
    "        print(f\"\\n🎤 Transcript type: {type(transcript)}\")\n",
    "        print(f\"🎤 Transcript length: {len(transcript) if isinstance(transcript, list) else 'Not a list'}\")\n",
    "        \n",
    "        if isinstance(transcript, list) and len(transcript) > 0:\n",
    "            print(\"\\n📝 First few transcript entries:\")\n",
    "            for i, entry in enumerate(transcript[:3]):\n",
    "                print(f\"\\nEntry {i+1}:\")\n",
    "                print(f\"  Type: {type(entry)}\")\n",
    "                if isinstance(entry, dict):\n",
    "                    print(f\"  Keys: {list(entry.keys())}\")\n",
    "                    # Show the actual structure\n",
    "                    print(f\"  Full entry: {json.dumps(entry, indent=4)}\")\n",
    "                else:\n",
    "                    print(f\"  Value: {entry}\")\n",
    "    \n",
    "    # Also check if there are other conversation-related fields\n",
    "    print(f\"\\n🔍 Other potential conversation fields:\")\n",
    "    for key in data.keys():\n",
    "        if 'conv' in key.lower() or 'message' in key.lower() or 'turn' in key.lower():\n",
    "            print(f\"  {key}: {type(data[key])}\")\n",
    "            \n",
    "else:\n",
    "    print(f\"❌ Error: {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "638c15cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRANSCRIPT STRUCTURE ANALYSIS ===\n",
      "Transcript type: <class 'list'>\n",
      "Transcript length: 3\n",
      "\n",
      "Entry 0:\n",
      "  Type: <class 'dict'>\n",
      "  Keys: ['role', 'message', 'tool_calls', 'tool_results', 'feedback', 'llm_override', 'time_in_call_secs', 'conversation_turn_metrics', 'rag_retrieval_info', 'llm_usage', 'interrupted', 'original_message', 'source_medium']\n",
      "    role: 'agent'...\n",
      "    message: 'What is on the heart and mind right now?'...\n",
      "    tool_calls: []...\n",
      "    tool_results: []...\n",
      "    feedback: None...\n",
      "    llm_override: None...\n",
      "    time_in_call_secs: 0...\n",
      "    conversation_turn_metrics: None...\n",
      "    rag_retrieval_info: None...\n",
      "    llm_usage: None...\n",
      "    interrupted: False...\n",
      "    original_message: None...\n",
      "    source_medium: None...\n",
      "\n",
      "Entry 1:\n",
      "  Type: <class 'dict'>\n",
      "  Keys: ['role', 'message', 'tool_calls', 'tool_results', 'feedback', 'llm_override', 'time_in_call_secs', 'conversation_turn_metrics', 'rag_retrieval_info', 'llm_usage', 'interrupted', 'original_message', 'source_medium']\n",
      "    role: 'user'...\n",
      "    message: \"I'm just seeing to see if this will do the transcript.\"...\n",
      "    tool_calls: []...\n",
      "    tool_results: []...\n",
      "    feedback: None...\n",
      "    llm_override: None...\n",
      "    time_in_call_secs: 6...\n",
      "    conversation_turn_metrics: None...\n",
      "    rag_retrieval_info: None...\n",
      "    llm_usage: None...\n",
      "    interrupted: False...\n",
      "    original_message: None...\n",
      "    source_medium: 'audio'...\n",
      "\n",
      "Entry 2:\n",
      "  Type: <class 'dict'>\n",
      "  Keys: ['role', 'message', 'tool_calls', 'tool_results', 'feedback', 'llm_override', 'time_in_call_secs', 'conversation_turn_metrics', 'rag_retrieval_info', 'llm_usage', 'interrupted', 'original_message', 'source_medium']\n",
      "    role: 'agent'...\n",
      "    message: 'Ah, a little test run to see if this captures your words… I love that curious spirit. So, now that ...\n",
      "    tool_calls: []...\n",
      "    tool_results: []...\n",
      "    feedback: None...\n",
      "    llm_override: None...\n",
      "    time_in_call_secs: 10...\n",
      "    conversation_turn_metrics: {'metrics': {'convai_llm_service_ttf_sentence': {'elapsed_time': 1.4634615876711905}, 'convai_llm_se...\n",
      "    rag_retrieval_info: None...\n",
      "    llm_usage: {'model_usage': {'gemini-2.5-flash': {'input': {'tokens': 1445, 'price': 0.00021675}, 'input_cache_r...\n",
      "    interrupted: True...\n",
      "    original_message: \"Ah, a little test run to see if this captures your words… I love that curious spirit. So, now that ...\n",
      "    source_medium: None...\n",
      "\n",
      "All unique keys: ['conversation_turn_metrics', 'feedback', 'interrupted', 'llm_override', 'llm_usage', 'message', 'original_message', 'rag_retrieval_info', 'role', 'source_medium', 'time_in_call_secs', 'tool_calls', 'tool_results']\n",
      "\n",
      "Sample entry structure:\n",
      "Keys: ['role', 'message', 'tool_calls', 'tool_results', 'feedback', 'llm_override', 'time_in_call_secs', 'conversation_turn_metrics', 'rag_retrieval_info', 'llm_usage', 'interrupted', 'original_message', 'source_medium']\n",
      "  role: 'agent'\n",
      "  message: 'What is on the heart and mind right now?'\n"
     ]
    }
   ],
   "source": [
    "# Examine transcript structure for frontend parsing\n",
    "print(\"=== TRANSCRIPT STRUCTURE ANALYSIS ===\")\n",
    "print(f\"Transcript type: {type(transcript)}\")\n",
    "print(f\"Transcript length: {len(transcript)}\")\n",
    "print()\n",
    "\n",
    "# Look at first few entries\n",
    "for i, entry in enumerate(transcript[:3]):\n",
    "    print(f\"Entry {i}:\")\n",
    "    print(f\"  Type: {type(entry)}\")\n",
    "    if isinstance(entry, dict):\n",
    "        print(f\"  Keys: {list(entry.keys())}\")\n",
    "        for key, value in entry.items():\n",
    "            print(f\"    {key}: {repr(value)[:100]}...\")\n",
    "    print()\n",
    "\n",
    "# Get all unique keys\n",
    "all_keys = set()\n",
    "for entry in transcript:\n",
    "    if isinstance(entry, dict):\n",
    "        all_keys.update(entry.keys())\n",
    "\n",
    "print(f\"All unique keys: {sorted(all_keys)}\")\n",
    "\n",
    "# Show a typical entry structure\n",
    "if transcript:\n",
    "    print(f\"\\nSample entry structure:\")\n",
    "    sample = transcript[0]\n",
    "    print(f\"Keys: {list(sample.keys())}\")\n",
    "    for key in ['speaker', 'role', 'message', 'text', 'content', 'user_id', 'agent_id']:\n",
    "        if key in sample:\n",
    "            print(f\"  {key}: {repr(sample[key])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scout",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
